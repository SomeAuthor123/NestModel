{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cc_model.load_datasets import *\n",
    "from cc_model.wl import *\n",
    "from cc_model.utils import nx_to_gt\n",
    "from cc_model.pagerank import all_pagerank\n",
    "from cc_model.rewire import *\n",
    "\n",
    "import networkx as nx\n",
    "from pathlib import Path\n",
    "import graph_tool.all as gt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"karate\",  #\"phonecalls\",\n",
    "            #\"HepPh\", \"AstroPh\", \"web-Google\", \"soc-Pokec\"\n",
    "#            \"deezer_HR\", \"deezer_HU\", \"deezer_RO\",\"tw_musae_DE\",\n",
    "#            \"tw_musae_ENGB\",\"tw_musae_FR\",\"lastfm_asia\",\"fb_ath\",\n",
    "#            \"fb_pol\", \"facebook_sc\"\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"/home/felix/projects/colorful_configuration/datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#edges, is_directed = load_dataset(dataset_path, \"soc-Pokec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon=1e-14\n",
    "max_iter = 300\n",
    "alpha=0.85"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pagerank(g, WL_round, outer_iter=10, verbosity=0):\n",
    "    \"\"\" Generate synthethic networks which have the same WL colors as g at round WL_round and return absolute error\"\"\"\n",
    "    mode = \"theirs\"\n",
    "    base_pagerank = all_pagerank(g, mode, epsilon=epsilon, max_iter=max_iter, alpha=alpha)\n",
    "    print(g.is_directed())\n",
    "    pageranks = []\n",
    "    GraphEnsemble = LocalHistogramRewiring(g, g.vp[f\"color_{WL_round}\"].get_array() )\n",
    "    for i in range(outer_iter):\n",
    "        if verbosity > 4:\n",
    "            print(\"    \",i)\n",
    "        new_g = GraphEnsemble.get_sample()\n",
    "        assert new_g.is_directed() == g.is_directed()\n",
    "        pagerank, err = all_pagerank(new_g, mode, epsilon=epsilon, max_iter=max_iter, alpha=alpha, return_err=True)\n",
    "\n",
    "        if verbosity > 0:\n",
    "            print(\"the error in pagerank iteration is:\\r\\n\", err)\n",
    "        pageranks.append(pagerank)\n",
    "    error_sum = [np.sum(np.abs(base_pagerank-pagerank)) for pagerank in pageranks]\n",
    "    if verbosity > 0:\n",
    "        print(\"max\", [np.max(np.abs(base_pagerank-pagerank)) for pagerank in pageranks])\n",
    "    return error_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MAE_for_iterations(g, edges, n_graphs):\n",
    "    means = []\n",
    "    stds = []\n",
    "    labelings = WL_fast(edges)\n",
    "    WL_iterations=len(labelings)\n",
    "    print(WL_iteration)\n",
    "    return\n",
    "    for WL_round in range(WL_iterations):\n",
    "        g_rewire = gt.Graph(g)\n",
    "        if verbosity>0:\n",
    "            print(WL_round)\n",
    "\n",
    "        MAEs = run_pagerank(g_rewire, WL_round, outer_iter=n_graphs, verbosity=0)\n",
    "        means.append(np.mean(MAEs))\n",
    "        stds.append(np.std(MAEs))\n",
    "    return means, stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pagerank_on_all_Graphs(n_graphs, verbosity=0):\n",
    "    list_means = []\n",
    "    list_stds = []\n",
    "    for dataset in datasets:\n",
    "        if dataset==None:\n",
    "            list_means.append([])\n",
    "            list_stds.append([])\n",
    "            continue\n",
    "        if verbosity>0:\n",
    "            print(dataset)\n",
    "        if verbosity > 3:\n",
    "            print(\"reading graph\")\n",
    "        G = load_gt_dataset_cached(dataset_path, dataset, verbosity=verbosity)\n",
    "        print(G.num_edges(), G.num_vertices())\n",
    "        \n",
    "        edges = G.get_edges()\n",
    "        if not G.is_directed():\n",
    "            edges2 = np.vstack((edges[:,1], edges[:,0])).T\n",
    "\n",
    "            edges = np.vstack((edges, edges2))\n",
    "        \n",
    "        if verbosity >3:\n",
    "            print(\"done reading graph\")\n",
    "            print(\"starting WL\")\n",
    "            print(repr(G))\n",
    "        #print(\"Done with WL\")\n",
    "        means, stds = get_MAE_for_iterations(G,edges, \n",
    "                                             n_graphs=n_graphs,)\n",
    "        list_means.append(means)\n",
    "        list_stds.append(stds)\n",
    "    return list_means, list_stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "karate\n",
      "78 34\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'WL_fast' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-c837622a9462>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mlist_means\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_stds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_pagerank_on_all_Graphs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbosity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-8-fe364df57b42>\u001b[0m in \u001b[0;36mcompute_pagerank_on_all_Graphs\u001b[0;34m(n_graphs, verbosity)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#print(\"Done with WL\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         means, stds = get_MAE_for_iterations(G,edges, \n\u001b[0m\u001b[1;32m     28\u001b[0m                                              n_graphs=n_graphs,)\n\u001b[1;32m     29\u001b[0m         \u001b[0mlist_means\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeans\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-1330d36fe4aa>\u001b[0m in \u001b[0;36mget_MAE_for_iterations\u001b[0;34m(g, edges, n_graphs)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mstds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mlabelings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWL_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medges\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mWL_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabelings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWL_iteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'WL_fast' is not defined"
     ]
    }
   ],
   "source": [
    "#%%snakeviz --new-tab\n",
    "\n",
    "verbosity=1\n",
    "list_means, list_stds = compute_pagerank_on_all_Graphs(42, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "for means, stds,label in zip(list_means, list_stds, datasets):\n",
    "    plt.errorbar(x=np.arange(len(means)),y=np.array(means)+1e-20, yerr=stds, label=label)\n",
    "plt.ylabel(\"MAE of pagerank\")\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.title(\"Convergence of pagerank for synthetic networks \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = load_gt_dataset_cached(dataset_path, \"karate\", verbosity=verbosity, force_reload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labelings(G):\n",
    "    WL_iterations, labelings = WL(G, add_labelings=True, verbosity=1)\n",
    "    arr_labelings = np.array(labelings, dtype=int)\n",
    "    return arr_labelings\n",
    "\n",
    "def get_sorted_labelings(G):\n",
    "    \"\"\"Computes the Wl labeling of a graph and sorts it such that the classes are in blocks\"\"\"\n",
    "    arr_labelings = get_labelings(G)\n",
    "    order = np.lexsort(arr_labelings[::-1,:])\n",
    "    print(order)\n",
    "    ordered_labelings = arr_labelings[:,order]\n",
    "    return order, ordered_labelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def to_in_neighbors(edges):\n",
    "    in_degrees = np.bincount(edges[:,1])\n",
    "\n",
    "    \n",
    "    starting_positions = np.empty(in_degrees.shape[0]+1, dtype=np.int32)\n",
    "    starting_positions[0]=0\n",
    "    starting_positions[1:] = in_degrees.cumsum()\n",
    "    current_index = starting_positions.copy()\n",
    "\n",
    "    in_neighbors = np.zeros(edges.shape[0], dtype=np.int32)\n",
    "    \n",
    "    for l, r in edges:\n",
    "        #if r < len(current_index)-1:\n",
    "        #    assert current_index[r]<=starting_positions[r+1], f\"{r} {current_index[r]} {starting_positions[r+1]} {current_index- starting_positions}\"\n",
    "        in_neighbors[current_index[r]] = l \n",
    "        current_index[r]+=1\n",
    "\n",
    "    return starting_positions, in_neighbors, in_degrees.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "to_in_neighbors(G.get_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.types import bool_\n",
    "import numpy\n",
    "@njit\n",
    "def primesfrom2to(n):\n",
    "    \"\"\" Input n>=6, Returns a array of primes, 2 <= p < n \"\"\"\n",
    "    size = int(n//3 + (n%6==2))\n",
    "    sieve = numpy.ones(size, dtype=bool_)\n",
    "    for i in range(1,int(n**0.5)//3+1):\n",
    "        if sieve[i]:\n",
    "            k=3*i+1|1\n",
    "            sieve[       k*k//3     ::2*k] = False\n",
    "            sieve[k*(k-2*(i&1)+4)//3::2*k] = False\n",
    "    arr =  ((3*numpy.nonzero(sieve)[0][1:]+1)|1)\n",
    "    output = np.empty(len(arr)+2, dtype=arr.dtype)\n",
    "    output[0]=2\n",
    "    output[1]=3\n",
    "    output[2:]=arr\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "primesfrom2to(int(10_000_000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def WL_fast(edges, max_iter=30):\n",
    "    startings, neighbors, _ = to_in_neighbors(edges)\n",
    "    return _WL_fast(startings, neighbors, max_iter)\n",
    "\n",
    "@njit\n",
    "def _WL_fast(startings, neighbors, max_iter=30):\n",
    "    \"\"\"WL using floating point operations with primes similar to \n",
    "    https://github.com/rmgarnett/fast_wl/blob/master/wl_transformation.m\n",
    "    \"\"\"\n",
    "    num_nodes = len(startings)-1\n",
    "    ln=np.log\n",
    "    n=num_nodes\n",
    "    if n >=6:\n",
    "        correction = np.ceil(ln(n)+ln(ln(n))-1)\n",
    "    else:\n",
    "        correction = 5\n",
    "    primes = primesfrom2to(num_nodes*correction)\n",
    "    log_primes = np.log(primes)\n",
    "    labels = np.zeros(num_nodes, dtype=np.uint32)\n",
    "    vals = np.ones(num_nodes)\n",
    "    \n",
    "    out = []\n",
    "    \n",
    "    last_num_colors = 1\n",
    "    for _ in range(max_iter):\n",
    "        lb = startings[0]\n",
    "        #print(vals)\n",
    "        for i in range(num_nodes):\n",
    "            lb = startings[i]\n",
    "            ub = startings[i+1]\n",
    "            for j in range(lb, ub):\n",
    "                vals[i]+=log_primes[labels[neighbors[j]]]\n",
    "        order = np.argsort(vals)\n",
    "        last_val = vals[order[0]]\n",
    "        num_colors = 0\n",
    "        #print(vals)\n",
    "        for node_id in order:\n",
    "            val = vals[node_id]\n",
    "            if last_val/val < 1-1e-16:\n",
    "                num_colors += 1\n",
    "                last_val = val\n",
    "\n",
    "            labels[node_id] = num_colors\n",
    "            vals[node_id] = primes[num_colors]\n",
    "        out.append(labels.copy())\n",
    "        if last_num_colors == num_colors:\n",
    "            break\n",
    "        else:\n",
    "            last_num_colors = num_colors\n",
    "            \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = load_gt_dataset_cached(dataset_path, \"web-Google\", verbosity=verbosity, force_reload=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def is_sorted(arr):\n",
    "    return np.all((arr[1:]-arr[:-1])>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WL_fast3(edges, max_iter=30):\n",
    "    edges2 = np.empty_like(edges)\n",
    "    edges2[:,0]= edges[:,1]\n",
    "    edges2[:,1]= edges[:,0]\n",
    "    startings, neighbors, max_degree = to_in_neighbors(edges2)\n",
    "    return _WL_fast3(startings, neighbors, max_degree, max_iter)\n",
    "@njit\n",
    "def _WL_fast3(startings, neighbors, max_degree, max_iter=30):\n",
    "    \"\"\"WL using floating point operations with primes similar to \n",
    "    https://github.com/rmgarnett/fast_wl/blob/master/wl_transformation.m\n",
    "    \"\"\"\n",
    "    raise ValueError(\"Did not work out as expected\")\n",
    "    num_nodes = len(startings)-1\n",
    "    ln=np.log\n",
    "    n=num_nodes\n",
    "    if n >=6:\n",
    "        # maybe remove the -1\n",
    "        correction = np.ceil(ln(n)+ln(ln(n)))\n",
    "    else:\n",
    "        correction = 5\n",
    "    primes = primesfrom2to(num_nodes*correction)\n",
    "    log_primes = np.log(primes)\n",
    "    deltas = log_primes.copy()\n",
    "    labels = np.zeros(num_nodes, dtype=np.uint32)\n",
    "    vals = np.ones(num_nodes)\n",
    "    out = []\n",
    "    order = np.arange(num_nodes)\n",
    "    order_updates = order.copy()\n",
    "    #skipped_updates = np.zeros(num_nodes, dtype=np.uint32)\n",
    "    num_updates = num_nodes\n",
    "    \n",
    "    partitions = np.zeros(num_nodes+1, dtype=np.uint32)\n",
    "    num_partitions = 1\n",
    "    partitions[0] = 0\n",
    "    partitions[1] = num_nodes\n",
    "    \n",
    "    affected_nodes = set()\n",
    "    affected_nodes.add(0)\n",
    "    affected_partitions = set()\n",
    "    affected_partitions.add(0)\n",
    "    #print(\"len\", len(log_primes))\n",
    "    last_num_colors = 1\n",
    "    \n",
    "    num_colors_sparse = 0\n",
    "    for x in range(max_iter):\n",
    "\n",
    "\n",
    "        #print(vals)\n",
    "        #print(labels[order])\n",
    "        #print(vals[order])\n",
    "        print(\"num_updates\", num_updates)\n",
    "        if num_updates > num_nodes//4:\n",
    "            for index in range(num_updates):# loop over all nodes that changed in last iter\n",
    "                i = order_updates[index]\n",
    "                lb = startings[i]\n",
    "                ub = startings[i+1]\n",
    "                for j in range(lb, ub): # propagate label of i to neighbor j\n",
    "                    vals[neighbors[j]]+=deltas[labels[i]]\n",
    "\n",
    "            # sort partitions such that the same values come after one another\n",
    "            for i in range(num_partitions):           \n",
    "                lb = partitions[i]\n",
    "                ub = partitions[i+1]\n",
    "                if ub-lb > 1:\n",
    "                    partition_order = np.argsort(vals[order[lb:ub]])\n",
    "                    order[lb:ub] = order[lb:ub][partition_order]\n",
    "                    \n",
    "                    num_colors = 0\n",
    "            num_partitions=0\n",
    "            last_index = 0\n",
    "            num_updates = 0\n",
    "            affected_nodes.clear()\n",
    "\n",
    "            last_val = vals[order[0]]\n",
    "            for i in range(len(order)):\n",
    "\n",
    "                node_id = order[i]\n",
    "\n",
    "                #i = order_index + skipped_updates[order_index]\n",
    "                #print(order_index, i)\n",
    "                val = vals[node_id]\n",
    "                if val!=last_val:\n",
    "                    num_partitions+=1\n",
    "                    last_index = i\n",
    "                    num_colors += 1\n",
    "                    partitions[num_colors]=i\n",
    "                    last_val = val\n",
    "                    deltas[last_index] = log_primes[last_index]-log_primes[labels[node_id]]\n",
    "                    #print(last_index, labels[node_id], deltas[last_index])\n",
    "                #assert last_index-labels[node_id]>0\n",
    "\n",
    "                if labels[node_id]!=last_index: #there is a need for updates \n",
    "                    order_updates[num_updates]=node_id\n",
    "                    num_updates+=1\n",
    "                else:\n",
    "                    vals[node_id] += last_index-labels[node_id]\n",
    "\n",
    "                labels[node_id] = last_index\n",
    "        else:\n",
    "            print(\"sparse\")\n",
    "            #print(partitions)\n",
    "            # sparse implementation\n",
    "            #affected_nodes.clear()\n",
    "            for index in range(num_updates):# loop over all nodes that changed in last iter\n",
    "                i = order_updates[index]\n",
    "                lb = startings[i]\n",
    "                ub = startings[i+1]\n",
    "                affected_nodes.add(i)\n",
    "                for j in range(lb, ub): # propagate label of i to neighbor j\n",
    "                    vals[neighbors[j]]+=deltas[labels[i]]\n",
    "                    affected_nodes.add(neighbors[j])\n",
    "            \n",
    "            affected_partitions.clear()\n",
    "            #assert is_sorted(partitions[:num_partitions])\n",
    "            for node_id in affected_nodes:\n",
    "                partition = np.searchsorted(partitions[:num_partitions], node_id+1)\n",
    "                affected_partitions.add(partition)\n",
    "            print(len(affected_partitions))\n",
    "            for p in affected_partitions:\n",
    "                #assert p>0\n",
    "                #assert p < num_partitions+1\n",
    "                lb = partitions[p-1]\n",
    "                ub = partitions[p]\n",
    "                #print(lb, ub)\n",
    "                #assert ub-lb > 0\n",
    "                if ub-lb > 1:\n",
    "                    partition_order = np.argsort(vals[order[lb:ub]])\n",
    "                    order[lb:ub] = order[lb:ub][partition_order]\n",
    "                \n",
    "                \n",
    "            num_colors = 0\n",
    "            num_partitions=0\n",
    "            last_index = 0\n",
    "            num_updates = 0\n",
    "            affected_nodes.clear()\n",
    "\n",
    "            last_val = vals[order[0]]\n",
    "            for i in range(len(order)):\n",
    "\n",
    "                node_id = order[i]\n",
    "\n",
    "                #i = order_index + skipped_updates[order_index]\n",
    "                #print(order_index, i)\n",
    "                val = vals[node_id]\n",
    "                if val!=last_val:\n",
    "                    num_partitions+=1\n",
    "                    last_index = i\n",
    "                    num_colors += 1\n",
    "                    partitions[num_colors]=i\n",
    "                    last_val = val\n",
    "                    deltas[last_index] = log_primes[last_index]-log_primes[labels[node_id]]\n",
    "                    #print(last_index, labels[node_id], deltas[last_index])\n",
    "                #assert last_index-labels[node_id]>0\n",
    "\n",
    "                if labels[node_id]!=last_index: #there is a need for updates \n",
    "                    order_updates[num_updates]=node_id\n",
    "                    num_updates+=1\n",
    "                    vals[node_id] += last_index-labels[node_id]\n",
    "                    affected_nodes.add(node_id)\n",
    "\n",
    "                labels[node_id] = last_index\n",
    "            #+primes[num_colors]\n",
    "        #print(vals[order])\n",
    "        out.append(labels.copy())\n",
    "        #print()\n",
    "        if last_num_colors == num_colors:\n",
    "            break\n",
    "        else:\n",
    "            last_num_colors = num_colors\n",
    "            \n",
    "    return out\n",
    "\n",
    "# another thing that annoys me, is that each iteration is O(edges)\n",
    "# but only a small number of nodes changes color\n",
    "\n",
    "\n",
    "# This above WL implementation can be sped up significantly by not \n",
    "# sorting the whole array in each iteration but sorting the array only once\n",
    "# this will give quite a boost as sorting is currently \n",
    "# the main cost of the algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WL_fast2(edges, max_iter=30):\n",
    "    edges2 = np.empty_like(edges)\n",
    "    edges2[:,0]= edges[:,1]\n",
    "    edges2[:,1]= edges[:,0]\n",
    "    startings, neighbors, max_degree = to_in_neighbors(edges2)\n",
    "    return _WL_fast2(startings, neighbors, max_degree, max_iter)\n",
    "@njit\n",
    "def is_sorted_fast(vals, order):\n",
    "    last_val = vals[order[0]]\n",
    "    for i in range(1, len(order)):\n",
    "        if vals[order[i]]<last_val:\n",
    "            return False\n",
    "        last_val = vals[order[i]]\n",
    "    return True\n",
    "\n",
    "@njit\n",
    "def _WL_fast2(startings, neighbors, max_degree, max_iter=30):\n",
    "    \"\"\"WL using floating point operations with primes similar to \n",
    "    https://github.com/rmgarnett/fast_wl/blob/master/wl_transformation.m\n",
    "    \"\"\"\n",
    "    num_nodes = len(startings)-1\n",
    "    ln=np.log\n",
    "    n=num_nodes\n",
    "    if n >=6:\n",
    "        # maybe remove the -1\n",
    "        correction = np.ceil(ln(n)+ln(ln(n)))\n",
    "    else:\n",
    "        correction = 5\n",
    "    primes = primesfrom2to(num_nodes*correction)\n",
    "    log_primes = np.log(primes)\n",
    "    deltas = log_primes.copy()\n",
    "    labels = np.zeros(num_nodes, dtype=np.uint32)\n",
    "    vals = np.ones(num_nodes)\n",
    "    out = []\n",
    "    order = np.arange(num_nodes)\n",
    "    order_updates = order.copy()\n",
    "    #skipped_updates = np.zeros(num_nodes, dtype=np.uint32)\n",
    "    num_updates = num_nodes\n",
    "    \n",
    "    partitions = np.zeros(num_nodes+1, dtype=np.uint32)\n",
    "    num_partitions = 1\n",
    "    partitions[0] = 0\n",
    "    partitions[1] = num_nodes\n",
    "    \n",
    "\n",
    "    #print(\"len\", len(log_primes))\n",
    "    last_num_colors = 1\n",
    "    \n",
    "    num_colors_sparse = 0\n",
    "    for x in range(max_iter):\n",
    "\n",
    "\n",
    "\n",
    "        #print(\"num_updates\", num_updates)\n",
    "        for index in range(num_updates):# loop over all nodes that changed in last iter\n",
    "            i = order_updates[index]\n",
    "            lb = startings[i]\n",
    "            ub = startings[i+1]\n",
    "            for j in range(lb, ub): # propagate label of i to neighbor j\n",
    "                vals[neighbors[j]]+=deltas[labels[i]]\n",
    "\n",
    "        # sort partitions such that the same values come after one another\n",
    "        for i in range(num_partitions):           \n",
    "            lb = partitions[i]\n",
    "            ub = partitions[i+1]\n",
    "            if ub-lb > 1:\n",
    "                if not is_sorted_fast(vals, order[lb:ub]):\n",
    "                    partition_order = np.argsort(vals[order[lb:ub]])\n",
    "                    order[lb:ub] = order[lb:ub][partition_order]\n",
    "\n",
    "        num_colors = 0\n",
    "        num_partitions=0\n",
    "        last_index = 0\n",
    "        num_updates = 0\n",
    "\n",
    "        last_val = vals[order[0]]\n",
    "        for i in range(len(order)):\n",
    "\n",
    "            node_id = order[i]\n",
    "\n",
    "\n",
    "            val = vals[node_id]\n",
    "            if val!=last_val:\n",
    "                num_partitions+=1\n",
    "                last_index = i\n",
    "                num_colors += 1\n",
    "                partitions[num_colors]=i\n",
    "                last_val = val\n",
    "                deltas[last_index] = log_primes[last_index]-log_primes[labels[node_id]]\n",
    "\n",
    "\n",
    "            if labels[node_id]!=last_index: #there is a need for updates \n",
    "                order_updates[num_updates]=node_id\n",
    "                num_updates+=1\n",
    "                vals[node_id] += last_index-labels[node_id]\n",
    "\n",
    "            labels[node_id] = last_index\n",
    "       \n",
    "        out.append(labels.copy())\n",
    "        #print()\n",
    "        if last_num_colors == num_colors:\n",
    "            break\n",
    "        else:\n",
    "            last_num_colors = num_colors\n",
    "            \n",
    "    return out\n",
    "\n",
    "# another thing that annoys me, is that each iteration is O(edges)\n",
    "# but only a small number of nodes changes color\n",
    "\n",
    "\n",
    "# This above WL implementation can be sped up significantly by not \n",
    "# sorting the whole array in each iteration but sorting the array only once\n",
    "# this will give quite a boost as sorting is currently \n",
    "# the main cost of the algorithm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,0):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = G.get_edges()\n",
    "if not G.is_directed():\n",
    "    edges2 = np.vstack((edges[:,1], edges[:,0])).T\n",
    "\n",
    "    edges = np.vstack((edges, edges2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "%%snakeviz --new-tab\n",
    "\n",
    "ret = WL_fast2(edges)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "num_updates 875713\n",
    "num_updates 714545\n",
    "num_updates 668286\n",
    "num_updates 451868\n",
    "num_updates 141547\n",
    "num_updates 30871\n",
    "num_updates 9214\n",
    "num_updates 5151\n",
    "num_updates 4674\n",
    "num_updates 4228\n",
    "num_updates 2285\n",
    "num_updates 2155\n",
    "num_updates 1244\n",
    "num_updates 1257\n",
    "num_updates 1169\n",
    "num_updates 987\n",
    "num_updates 965\n",
    "num_updates 951\n",
    "num_updates 26\n",
    "num_updates 24\n",
    "num_updates 10\n",
    "num_updates 9\n",
    "num_updates 8\n",
    "num_updates 7\n",
    "num_updates 6\n",
    "num_updates 5\n",
    "num_updates 3\n",
    "num_updates 2\n",
    "num_updates 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maxs(l):\n",
    "    return [x.max() for x in l]\n",
    "\n",
    "def get_uniques(l):\n",
    "    return [len(np.unique(x)) for x in l]\n",
    "get_uniques(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "WL_iterations, labelings = WL(G, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order, ordered_labelings = get_sorted_labelings(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_labelings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_block(arr):\n",
    "    \"\"\"Checks whether a labeling is block ordered\n",
    "    \n",
    "    AACCBBBB is block ordered\n",
    "    ABACCC is not block ordered\n",
    "    \"\"\"\n",
    "    previous_seen = set()\n",
    "    last_val = 0\n",
    "    for i, val in enumerate(arr):\n",
    "        if val == last_val:\n",
    "            continue\n",
    "        else:\n",
    "            last_val=val\n",
    "            if val in previous_seen:\n",
    "                #print(\"AAAA\", val, arr[i-10:i+10])\n",
    "                return False\n",
    "            else:\n",
    "                previous_seen.add(val)\n",
    "    return True\n",
    "\n",
    "for i in range(ordered_labelings.shape[0]):\n",
    "    arr = ordered_labelings[i,:]\n",
    "    #print(np.nonzero(arr==4))\n",
    "    print(np.count_nonzero(arr[1:]-arr[0:-1]))\n",
    "    assert is_block(arr)\n",
    "    print(is_block(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_order = np.empty_like(order)\n",
    "inv_order[order]=np.arange(len(inv_order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_order2 = np.empty_like(order)\n",
    "for old_label, new_label in enumerate(order):\n",
    "    inv_order2[new_label] = old_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(np.abs(inv_order-inv_order2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def relabel_edges(inv_order, edges):\n",
    "    print(edges.shape)\n",
    "    for i in range(edges.shape[0]):\n",
    "        edges[i][0] = inv_order[edges[i][0]]\n",
    "        edges[i][1] = inv_order[edges[i][1]]\n",
    "    return edges    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_order3 = np.arange(len(order))[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = relabel_edges(inv_order, G.get_edges())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WL_fast(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate = defaultdict(set)\n",
    "validate2 = defaultdict(set)\n",
    "for val, key in zip(edges[:,0], G.get_edges()[:,0]):\n",
    "    validate[val].add(key)\n",
    "    validate2[key].add(val)\n",
    "for val, key in zip(edges[:,1], G.get_edges()[:,1]):\n",
    "    validate[val].add(key)\n",
    "    validate2[key].add(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g2 = gt.Graph(directed=G.is_directed())\n",
    "g2.add_edge_list(edges)\n",
    "g2.num_edges()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edge_id(labels, edges):\n",
    "    max_label = labels.max()\n",
    "    edge_id =  max_label*(labels[edges[:,0]]) + labels[edges[:,1]]\n",
    "    print(edge_id.shape)\n",
    "    return edge_id\n",
    "\n",
    "@njit\n",
    "def get_edge_id2(labels, edges, out):\n",
    "    d = {(0, 0) : 0}\n",
    "    del d[(0, 0)]\n",
    "    is_mono = {0 : True}\n",
    "    for i in range(len(edges)):\n",
    "        e1, e2 = edges[i,:]\n",
    "        tpl = (labels[e1], labels[e2])\n",
    "        if not tpl in d:\n",
    "            n = len(d)\n",
    "            d[tpl] = n\n",
    "            if labels[e1] == labels[e2]:\n",
    "                is_mono[n] = True\n",
    "        out[i] = d[tpl]    \n",
    "    return out, is_mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shape(arr):\n",
    "    return arr.shape\n",
    "\n",
    "def get_shapes(arr):\n",
    "    return list(map(get_shape, arr))\n",
    "\n",
    "def get_lens(arr):\n",
    "    return list(map(len, arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_dead_edges(labels, edges, dead_colors):\n",
    "    is_dead_end1 = dead_colors[labels[edges[:,0]]]\n",
    "    is_dead_end2 = dead_colors[labels[edges[:,1]]]\n",
    "    return np.logical_or(is_dead_end1, is_dead_end2)\n",
    "\n",
    "\n",
    "\n",
    "def get_dead_edges_full(edges, labelings, edges_classes):\n",
    "    \"\"\" Computes the first index in which an edge is dead\n",
    "    result [1,0,2] means 1st edge is dead after iteration 1, second edge is dead after iteration 0, \n",
    "                     third edge is dead after iteration 2\n",
    "    \n",
    "    \"\"\"\n",
    "    # maybe omit minlength\n",
    "    dead_colors = [np.bincount(arr.ravel(), minlength=arr.max())==1 for arr in labelings]\n",
    "    dead_edges = [get_dead_edges(labelings[i,:], edges, dead_colors[i]) for i in range(len(dead_colors))]\n",
    "    # maybe bincount is very inefficient!\n",
    "    dead_ids = [np.bincount(edges_classes[i], minlength = edges_classes[i].max()) <= 1 for i in range(len(dead_edges))]\n",
    "    dead_edges2 = [dead_ids[i][edges_classes[i]] for i in range(len(dead_edges))]\n",
    "    #print(get_shapes(dead_edges), get_shapes(dead_edges2))\n",
    "    \n",
    "    dead_edges_final = np.array([np.logical_or(a, b) for a, b in zip(dead_edges, dead_edges2)])\n",
    "    #print(dead_edges_final)\n",
    "    return dead_edges_final#, np.sum(dead_edges_final, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "def sort_edges(edges, labelings, directed = True):\n",
    "    \"\"\"Sort edges such that that edges of similar classes are consecutive\n",
    "    \n",
    "    additionally puts dead edges at the end\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # WARNING If network is undirected edges need to be sorted first\n",
    "    if directed == False:\n",
    "        raise ValueError()\n",
    "        \n",
    "\n",
    "    #edges_classes = [get_edge_id(labelings[i,:], edges) for i in range(labelings.shape[0])]\n",
    "    edges_classes = []\n",
    "    is_mono = []\n",
    "    for i in range(labelings.shape[0]):\n",
    "        edge_class, mono = get_edge_id2(labelings[i,:], edges, np.empty(len(edges), dtype=np.uint32))\n",
    "        edges_classes.append(edge_class)\n",
    "        is_mono.append(mono)\n",
    "    \n",
    "    dead_indicator = get_dead_edges_full(edges, labelings, edges_classes)\n",
    "    tmp = list(chain.from_iterable(zip(edges_classes, dead_indicator)))\n",
    "    print(list(tmp))\n",
    "    edges_classes_arr = np.vstack(edges_classes)\n",
    "    to_sort_arr = np.vstack(tmp)#[dead_ids]+ edges_classes)\n",
    "    \n",
    "    # sort edges such that each of the classes are in order\n",
    "    edge_order = np.lexsort(to_sort_arr[::-1,:])\n",
    "    #print(edge_order)\n",
    "    edges_ordered = edges[edge_order,:]\n",
    "    return edges_ordered, edges_classes_arr[:, edge_order].T, dead_indicator[:, edge_order], is_mono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelings2 = get_labelings(g2)#[:,order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(labelings2.shape[0]):\n",
    "    arr = labelings2[i,:]\n",
    "    #print(np.nonzero(arr==4))\n",
    "    #print(np.count_nonzero(arr[1:]-arr[0:-1]))\n",
    "    print(is_block(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_ordered, edges_classes, dead_arr, is_mono = sort_edges(edges, labelings2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(edges_classes.shape[1]):\n",
    "    print(is_block(edges_classes[:18561,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.bincount(edges_classes[:18561,2])\n",
    "inds = arr >0\n",
    "print(arr[inds].min())\n",
    "print(is_block(arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_classes[:,2].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dead_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@njit\n",
    "def _get_block_indices(arr_in, is_dead, out):\n",
    "    \"\"\"Returns the indices of block changes in arr\n",
    "    input [4,4,2,2,3,5]\n",
    "    output = [0,2,4,5,6]\n",
    "    lower inclusive, upper exclusive\n",
    "    \n",
    "    \"\"\"\n",
    "    indices = np.arange(len(arr_in))[~is_dead]\n",
    "    arr = arr_in[~is_dead]\n",
    "    #print(arr)\n",
    "    #print(indices)\n",
    "    #print()\n",
    "    if len(arr)==0:\n",
    "        return out[:0, :]\n",
    "    last_val = arr[0]\n",
    "    out[0,0] = indices[0]\n",
    "    n=0\n",
    "    last_index=0\n",
    "    for i, val in zip(indices, arr):\n",
    "\n",
    "        if val == last_val:\n",
    "            last_index=i\n",
    "            continue\n",
    "        else:\n",
    "            last_val=val\n",
    "            out[n,1]=last_index+1\n",
    "            out[n+1,0]=i\n",
    "            n+=1\n",
    "            last_index=i\n",
    "    out[n,1] = last_index+1\n",
    "    if out[n,1]-out[n,0]>1:\n",
    "        n+=1\n",
    "    return out[:n,:]\n",
    "\n",
    "def check_blocks(out_arr):\n",
    "    block_lengths = out_arr[1:]-out_arr[0:len(out_arr)-1]\n",
    "    inds = block_lengths <= 1\n",
    "    assert np.all(block_lengths>1), f\"{block_lengths[inds]} {out_arr[1:][inds]}\"\n",
    "        \n",
    "\n",
    "#@njit\n",
    "def get_block_indices(edges_classes, dead_arrs):\n",
    "    \"\"\"Returns an arr that contains the start and end of blocks\"\"\"\n",
    "    out = []\n",
    "    for arr, dead_arr in zip(edges_classes.T, dead_arrs):\n",
    "        \n",
    "        out_arr =_get_block_indices(arr, dead_arr, np.empty((len(arr),2), dtype=np.int32))\n",
    "        #print(arr)\n",
    "        #print(dead_arr)\n",
    "        #c=45673\n",
    "        #d=3\n",
    "        #print(arr[c-d:c+d])\n",
    "        #print(dead_arr[c-d:c+d])\n",
    "        #print(out_arr)\n",
    "        \n",
    "        #check_blocks(out_arr)\n",
    "        print(dead_arr.sum()+np.sum(out_arr[:,1]-out_arr[:,0]))\n",
    "        print(\"block\", np.sum(out_arr[:,1]-out_arr[:,0]))\n",
    "        #print(len(edges_classes))\n",
    "        out.append(out_arr)\n",
    "        \n",
    "    \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=get_block_indices(edges_classes, dead_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def rewire_mono(edges, n_rewire):\n",
    "    delta = len(edges)\n",
    "    \n",
    "    \n",
    "    for _ in range(n_rewire):\n",
    "        index1 = np.random.randint(0, delta)\n",
    "        offset = np.random.randint(1, delta)\n",
    "        i2_1 = np.random.randint(0, 2)\n",
    "        i2_2 = 1 - i2_1\n",
    "        index2 = (index1 + offset) % (delta)\n",
    "        e1_l, e1_r = edges[index1,:]\n",
    "        e2_l = edges[index2, i2_1]\n",
    "        e2_r = edges[index2, i2_2]\n",
    "        \n",
    "        \n",
    "        if (e1_r == e2_r) or (e1_l == e2_l): # swap would do nothing\n",
    "            continue\n",
    "            \n",
    "        if (e1_l == e2_r) or (e1_r == e2_l): # no self loops after swab\n",
    "            continue\n",
    "        \n",
    "        can_flip = True\n",
    "        for i in range(len(edges)):\n",
    "            ei_l, ei_r = edges[i,:]\n",
    "            if ((ei_l == e1_l and ei_r == e2_r) or (ei_l == e2_l and ei_r == e1_r)\n",
    "            or (ei_l == e1_r and ei_r == e2_l) or (ei_l == e2_r and ei_r == e1_l)):\n",
    "                can_flip = False\n",
    "                break\n",
    "        if can_flip:\n",
    "            edges[index1, 1] = e2_r\n",
    "            edges[index2, 0] = e2_l\n",
    "            edges[index2, 1] = e1_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.typed import List,Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def rewire_mono2(edges, n_rewire):\n",
    "    delta = len(edges)\n",
    "    neigh = Dict()\n",
    "    neigh[0] = List([-1])\n",
    "    del neigh[0]\n",
    "    for l,r in edges:\n",
    "        if l not in neigh:\n",
    "            tmp = List([-1])\n",
    "            tmp.pop()\n",
    "            neigh[l] = tmp\n",
    "        if r not in neigh:\n",
    "            tmp = List([-1])\n",
    "            tmp.pop()\n",
    "            neigh[r] = tmp\n",
    "        neigh[l].append(r)\n",
    "        neigh[r].append(l)\n",
    "    \n",
    "    # start:\n",
    "    # e1_l <-> e1_r\n",
    "    # e2_l <-> e2_r\n",
    "    # after\n",
    "    # e1_l <-> e2_r\n",
    "    # e2_l <-> e1_r\n",
    "    \n",
    "    for _ in range(n_rewire):\n",
    "        index1 = np.random.randint(0, delta)\n",
    "        offset = np.random.randint(1, delta)\n",
    "        i2_1 = np.random.randint(0, 2)\n",
    "        i2_2 = 1 - i2_1\n",
    "        index2 = (index1 + offset) % (delta)\n",
    "        e1_l, e1_r = edges[index1,:]\n",
    "        e2_l = edges[index2, i2_1]\n",
    "        e2_r = edges[index2, i2_2]\n",
    "        \n",
    "        \n",
    "        if (e1_r == e2_r) or (e1_l == e2_l): # swap would do nothing\n",
    "            continue\n",
    "            \n",
    "        if (e1_l == e2_r) or (e1_r == e2_l): # no self loops after swab\n",
    "            continue\n",
    "        \n",
    "        can_flip = True\n",
    "        if e2_r in neigh[e1_l] or e1_r in neigh[e2_l]:\n",
    "            can_flip = False\n",
    "\n",
    "        if can_flip:\n",
    "            edges[index1, 1] = e2_r\n",
    "            edges[index2, 0] = e2_l\n",
    "            edges[index2, 1] = e1_r\n",
    "            neigh[e1_l].remove(e1_r)\n",
    "            neigh[e1_r].remove(e1_l)\n",
    "            \n",
    "            neigh[e2_l].remove(e2_r)\n",
    "            neigh[e2_r].remove(e2_l)\n",
    "            \n",
    "            neigh[e1_l].append(e2_r)\n",
    "            neigh[e2_r].append(e1_l)\n",
    "            \n",
    "            neigh[e2_l].append(e1_r)\n",
    "            neigh[e1_r].append(e2_l)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "edges = np.array([[1,2],[3,4]])\n",
    "for _ in range(10):\n",
    "    rewire_mono2(edges,1)\n",
    "    print(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.randint(0, 2, size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rewire_bipartite(edges, lower, upper, n_rewire):\n",
    "    \"\"\"rewires a two class graph\n",
    "    \n",
    "    notice that also a one class _directed_ graph is a two class graph\n",
    "    \"\"\"\n",
    "    if upper-lower < 2:\n",
    "        raise ValueError\n",
    "    \n",
    "    _rewire_bipartite(edges[lower:upper], n_rewire)\n",
    "    print(edges[lower:upper])\n",
    "    \n",
    "@njit\n",
    "def _rewire_bipartite(edges, n_rewire):\n",
    "    # can do further optimization because the left side is always in a block\n",
    "    #  => can limit search range\n",
    "    \n",
    "    delta = len(edges)\n",
    "\n",
    "    \n",
    "    for _ in range(n_rewire):\n",
    "        index1 = np.random.randint(0, delta)\n",
    "        offset = np.random.randint(1, delta)\n",
    "        index2 = (index1 + offset) % (delta)\n",
    "        e1_l, e1_r = edges[index1,:]\n",
    "        e2_l, e2_r = edges[index2 ,:]\n",
    "        \n",
    "        if (e1_r == e2_r) or (e1_l == e2_l): # swap would do nothing\n",
    "            continue\n",
    "            \n",
    "        if (e1_l == e2_r) or (e1_r == e2_l): # no self loops after swab\n",
    "            continue\n",
    "        \n",
    "        can_flip = True\n",
    "        for i in range(len(edges)):\n",
    "            ei_l, ei_r = edges[i,:]\n",
    "            if (ei_l == e1_l and ei_r == e2_r) or (ei_l == e2_l and ei_r == e1_r):\n",
    "                can_flip = False\n",
    "                break\n",
    "        if can_flip:\n",
    "            edges[index1, 1] = e2_r\n",
    "            edges[index2, 1] = e1_r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def _rewire_bipartite_large(edges, n_rewire):\n",
    "    # can do further optimization because the left side is always in a block\n",
    "    #  => can limit search range\n",
    "    \n",
    "    delta = len(edges)\n",
    "    neigh = Dict()\n",
    "    neigh[0] = List([-1])\n",
    "    del neigh[0]\n",
    "    for l,r in edges:\n",
    "        if l not in neigh:\n",
    "            tmp = List([-1])\n",
    "            tmp.pop()\n",
    "            neigh[l] = tmp\n",
    "        neigh[l].append(r)\n",
    "    \n",
    "    for _ in range(n_rewire):\n",
    "        index1 = np.random.randint(0, delta)\n",
    "        offset = np.random.randint(1, delta)\n",
    "        index2 = (index1 + offset) % (delta)\n",
    "        e1_l, e1_r = edges[index1,:]\n",
    "        e2_l, e2_r = edges[index2 ,:]\n",
    "        \n",
    "        if (e1_r == e2_r) or (e1_l == e2_l): # swap would do nothing\n",
    "            continue\n",
    "            \n",
    "        if (e1_l == e2_r) or (e1_r == e2_l): # no self loops after swab\n",
    "            continue\n",
    "        \n",
    "        can_flip = True\n",
    "        if e2_r in neigh[e1_l] or e1_r in neigh[e2_l]:\n",
    "            can_flip = False\n",
    "\n",
    "        if can_flip:\n",
    "            edges[index1, 1] = e2_r\n",
    "            edges[index2, 1] = e1_r\n",
    "            \n",
    "            neigh[e1_l].remove(e1_r)\n",
    "            neigh[e2_l].remove(e2_r)\n",
    "            neigh[e1_l].append(e2_r)\n",
    "            neigh[e2_l].append(e1_r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def rewire_numba(edges, edge_class, current_mono, block, is_directed):\n",
    "    # assumes edges to be ordered\n",
    "    \n",
    "    \n",
    "\n",
    "    #block = block_indices[depth]\n",
    "    #edge_class = edges_classes[:,depth]\n",
    "    #curr_dead = dead_arr[depth,:]\n",
    "    #current_mono = is_mono[depth]\n",
    "    #print(edge_class)\n",
    "    #print(np.bincount(edges.ravel()))\n",
    "    #original_edges = edges.copy()\n",
    "    total_a = 0\n",
    "    total_b = 0\n",
    "    #print(\"block\", (block[:,1]-block[:,0]).sum())\n",
    "    deltas=[]\n",
    "    #print(block.shape, len(block), block.dtype)\n",
    "    for i in range(len(block)):\n",
    "        lower = block[i,0]\n",
    "        upper = block[i,1]\n",
    "        delta=upper-lower\n",
    "        \n",
    "        deltas.append(delta)\n",
    "        current_class = edge_class[lower]\n",
    "\n",
    "        if not is_directed and current_class in current_mono:\n",
    "            total_a += int(delta)\n",
    "            #print(f\"---{delta}\")\n",
    "            if delta< 50:\n",
    "                rewire_mono(edges[lower:upper], np.random.randint(delta, 2*delta))\n",
    "            else:\n",
    "                rewire_mono2(edges[lower:upper], np.random.randint(delta, 2*delta))\n",
    "        else:\n",
    "            total_b += int(delta)\n",
    "            #print(f\"-{delta}\")\n",
    "            if delta< 50:\n",
    "                _rewire_bipartite(edges[lower:upper], np.random.randint(delta, 2*delta))\n",
    "            else:\n",
    "                _rewire_bipartite_large(edges[lower:upper], np.random.randint(delta, 2*delta))\n",
    "\n",
    "    \n",
    "    #print(np.max(deltas))\n",
    "    #print(block[:,1]-block[:,0]-np.array(deltas))\n",
    "    #print(\"both\", total_a+total_b)\n",
    "    #print(\"mono\", total_a)\n",
    "    #print(\"bipa\", total_b)\n",
    "    #print(edges-original_edges!=0)\n",
    "    #print(np.bincount(edges.ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_lens(is_mono)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dead_arr)-1):\n",
    "    print(np.all(np.logical_or(~dead_arr[i,:], dead_arr[i+1,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%snakeviz --new-tab\n",
    "\n",
    "block_indices = get_block_indices(edges_classes, dead_arr)\n",
    "all_edges = []\n",
    "for depth  in range(8,-1,-1):\n",
    "    inner_edges = []\n",
    "    for inner_iter  in range(1):\n",
    "        #print(depth)#, inner_iter, dead_arr[depth,:].sum())\n",
    "        t0 = time.time()\n",
    "\n",
    "        rewire_numba(edges_ordered, edges_classes[:,depth], is_mono[depth], block_indices[depth], G.is_directed())\n",
    "        inner_edges.append(edges_ordered.copy())\n",
    "        t1 = time.time()\n",
    "        total_n = t1-t0\n",
    "        print(depth, total_n)\n",
    "    all_edges.append(inner_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "a,b = WL_fast(all_edges[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_sorted(all_edges[0][0][:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_sorted(arr):\n",
    "    return np.all((arr[1:]-arr[:-1])>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(block_indices[1][:,1]-block_indices[1][:,0]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(3)\n",
    "lower = 0\n",
    "upper = 20\n",
    "print(edges_ordered[lower:upper])\n",
    "\n",
    "\n",
    "\n",
    "rewire_bipartite(edges_ordered.copy(), lower, upper, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dead_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify dead_edges\n",
    "\n",
    "#edges_ordered, edge_classes\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_classes2 = np.hstack([relabel_edges(ordered_labelings[i,:], edges_ordered.copy()) for i in range(ordered_labelings.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_classes2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_sorted(arr):\n",
    "    return np.all((arr[1:]-arr[0:-1])>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[is_sorted(a) for a in labelings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2 & 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (conda_net)",
   "language": "python",
   "name": "conda_net"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
